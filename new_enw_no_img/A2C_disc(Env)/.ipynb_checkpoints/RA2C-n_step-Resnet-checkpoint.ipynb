{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d3d49e-5464-4726-8c3e-e84c5b357047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from Ractor_critic import ActorCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34fc9fca-c251-49e4-b7db-b6770976d05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkhomenko/PycharmProjects/RL/venv/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from enviroment_class import CustomEnv\n",
    "\n",
    "env = CustomEnv(obstacle_turn = True,\n",
    "                vizualaze     = True,\n",
    "                Total_war     = True,\n",
    "                inp_dim       = 500,\n",
    "                head_velocity = 0.001,#0.005\n",
    "                num_obs       = 5,\n",
    "                num_enemy     = 1,\n",
    "                size_obs      = [50, 60],\n",
    "                rew_col       = -70,\n",
    "                rew_win       = 100,\n",
    "                rew_defeat    = -100,\n",
    "                steps_limit   = 1000,\n",
    "                EnemyLidSet   = [45,90],\n",
    "                AllyLidSet    = [40, 90])\n",
    "_ = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1483756-456a-43a7-93e7-ecab24fd4d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkhomenko/PycharmProjects/RL/venv/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "agent = ActorCritic(lr = 0.0005, \n",
    "                    input_conv_dims = (15,3),\n",
    "                    allias_state = 5, \n",
    "                    enemy_state = 5, \n",
    "                    n_actions  = env.action_space.n,\n",
    "                    cuda = 'cuda:0',\n",
    "                    gamma = 0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24782d7-8cc5-4fd9-b149-075aafbfa56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "save_score = -np.inf\n",
    "\n",
    "n_steps = 5000\n",
    "T_MAX = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8291693-d031-4fa6-9d56-30f6b9a5d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  reward: -570.4774890452662  avg score: -570.4774890452662  loss: (-750.4937744140625, 3938.723388671875)\n",
      ".... saving models ....\n",
      "1  reward: -194.0879565232863  avg score: -382.28272278427625  loss: (-1704.266845703125, 3855.711669921875)\n",
      ".... saving models ....\n",
      "2  reward: -290.418617716693  avg score: -351.6613544284152  loss: (-133.16024780273438, 4383.40625)\n",
      ".... saving models ....\n",
      "3  reward: -32.06923008591918  avg score: -271.7633233427912  loss: (-1326.242919921875, 1868.22314453125)\n",
      ".... saving models ....\n",
      "4  reward: 251.63586693481358  avg score: -167.08348528727024  loss: (-460.58819580078125, 3003.79150390625)\n",
      ".... saving models ....\n",
      "5  reward: -83.26474228376397  avg score: -153.11369478668587  loss: (-1793.795166015625, 2486.399658203125)\n",
      ".... saving models ....\n",
      "6  reward: -140.62449335540867  avg score: -151.32952315364628  loss: (-808.1724243164062, 3494.767333984375)\n",
      ".... saving models ....\n",
      "7  reward: 78.46101391626533  avg score: -122.6057060199073  loss: (-1184.864501953125, 2687.182373046875)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_steps):\n",
    "    observation = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    ep_steps = 0\n",
    "    r = 0\n",
    "    hx, cx = T.zeros(64).to(agent.actor.device), T.zeros(64).to(agent.actor.device)\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        action, hx, cx = agent.choose_action(observation, hx, cx)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        agent.store_mem(reward)\n",
    "        \n",
    "        r += reward\n",
    "        ep_steps+=1\n",
    "        \n",
    "        if ep_steps % T_MAX == 0 or done:\n",
    "            hx, cx = hx.detach(), cx.detach()\n",
    "            loss = agent.learn(observation, done)\n",
    "            \n",
    "    scores.append(r)\n",
    "    \n",
    "    avg_score = np.mean(scores[-100:])\n",
    "    if avg_score > save_score:\n",
    "        agent.save_models()\n",
    "        save_score = avg_score\n",
    "    \n",
    "    if not bool(i%10):clear_output()\n",
    "    print(i,' reward:', r,' avg score:', avg_score,' loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f7dde-5a0c-4776-904f-69f9c5e2f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c641d-f052-43a2-8de8-6fa139dface0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_learning_curve(scores, x, figure_file):\n",
    "    # loss_avg = np.zeros(len(scores))\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "        # loss_avg[i] = np.mean(loss[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    # plt.plot(x, loss_avg)\n",
    "    plt.title('Average of previos 100 games')\n",
    "    plt.savefig(figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34751e3a-0fd8-4776-9f9b-5e28dcf50eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list = [z for z in range(n_steps)]\n",
    "\n",
    "plot_learning_curve(scores, steps_list, 'A3C_pong_final.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbed50-a819-4f19-a94f-3b95d86db009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enviroment_class import CustomEnv\n",
    "\n",
    "env = CustomEnv(obstacle_turn = True,\n",
    "                vizualaze     = False,\n",
    "                Total_war     = True,\n",
    "                inp_dim       = 500,\n",
    "                head_velocity = 0.0005,#0.005\n",
    "                num_obs       = 5,\n",
    "                num_enemy     = 1,\n",
    "                size_obs      = [50, 60],\n",
    "                rew_col       = -70,\n",
    "                rew_win       = 100,\n",
    "                rew_defeat    = -100,\n",
    "                steps_limit   = 1000,\n",
    "                EnemyLidSet   = [45,90],\n",
    "                AllyLidSet    = [40, 90])\n",
    "_ = env.reset()\n",
    "\n",
    "\n",
    "env.get_statistic( model = agent, num_games = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0d5a9-c910-4b04-b7e2-eecfe1b0a22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37856cc1-435c-49a4-8c63-f3e6ca9b2bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fe445-3929-43b2-8ea8-8f9c80a7f0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f15d6d-30a3-4d78-8a04-7a3c447cd13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadaa3a8-ce98-41b2-9ba4-0704d1932604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b705b-7d29-4399-a935-10b62ea9aff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a98f6-662a-47dc-b64f-cff200c2d25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
