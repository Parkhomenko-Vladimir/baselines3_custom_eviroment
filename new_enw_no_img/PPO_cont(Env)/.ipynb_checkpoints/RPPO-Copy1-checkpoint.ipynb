{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f3e253-d41e-40f5-82c8-f90e789bf02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import torch as T\n",
    "\n",
    "from RPPO import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c43f32-32b3-4fdb-bf21-0543dd25254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkhomenko/PycharmProjects/RL/venv/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float16\u001b[0m\n",
      "  logger.warn(\n",
      "/home/parkhomenko/PycharmProjects/RL/venv/lib/python3.10/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from enviroment_class import CustomEnv\n",
    "\n",
    "env = CustomEnv(obstacle_turn = True,\n",
    "                vizualaze     = False,\n",
    "                Total_war     = True,\n",
    "                inp_dim       = 500,\n",
    "                head_velocity = 0.005, #0.005\n",
    "                num_obs       = 5,\n",
    "                num_enemy     = 1,\n",
    "                size_obs      = [50, 60],\n",
    "                rew_col       = -70,\n",
    "                rew_win       = 100,\n",
    "                rew_defeat    = -100,\n",
    "                steps_limit   = 1000,\n",
    "                EnemyLidSet   = [45,90],\n",
    "                AllyLidSet    = [40, 90])\n",
    "\n",
    "_ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb8ad98-f093-4793-ae2c-883079abe442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkhomenko/PycharmProjects/RL/venv/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "N = 20\n",
    "n_epochs = 3\n",
    "alpha = 0.0003  ##0.003\n",
    "\n",
    "agent = Agent(input_conv_dims = (15,3),\n",
    "              allias_state = 5,\n",
    "              enemy_state = 5, \n",
    "              n_actions = 2,\n",
    "              alpha=alpha,\n",
    "              cuda = 'cuda:0',\n",
    "              n_epochs=n_epochs)\n",
    "\n",
    "n_games = 5000\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "score_history = []\n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ba015-bea3-401f-9a59-d92152f01c0d",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c00b8-baba-45d6-9e97-9132c15990fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  10 score 19.8 avg score -14.3 time step 500 learning_steps 25\n",
      "episode  11 score 51.8 avg score -8.8 time step 541 learning_steps 27\n",
      "episode  12 score -2097.8 avg score -169.5 time step 1541 learning_steps 77\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    score = 0\n",
    "    hx, cx = T.zeros(64).to(agent.actor.device), T.zeros(64).to(agent.actor.device)\n",
    "    H, C = T.zeros(64).to(agent.actor.device), T.zeros(64).to(agent.actor.device)\n",
    "    \n",
    "    agent.memory.clear_memory()\n",
    "    \n",
    "    while not done:\n",
    "        action, prob, val, hx, cx = agent.choose_action(observation, hx, cx)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        \n",
    "        state = observation['img']\n",
    "        a = observation['posRobot']\n",
    "        e = observation['target']\n",
    "        agent.remember(state, a, e, action, prob, val, reward, done)\n",
    "        \n",
    "        if n_steps % N == 0:\n",
    "            agent.learn(H, C)\n",
    "            learn_iters += 1\n",
    "            H = hx.detach()\n",
    "            C = cx.detach()\n",
    "            \n",
    "        observation = observation_\n",
    "        \n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        agent.save_models()\n",
    "    \n",
    "    if not bool(i%10):clear_output()\n",
    "    \n",
    "    print('episode ', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
    "          'time step', n_steps, 'learning_steps', learn_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658631d0-f92f-4d86-90c9-92218651ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(x, scores, filename, lines=None):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111, label=\"1\")\n",
    "    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "\n",
    "    ax.set_xlabel(\"Num games\", color=\"C0\")\n",
    "    ax.set_ylabel(\"Epsilon\", color=\"C0\")###################\n",
    "    ax.tick_params(axis='x', colors=\"C0\")\n",
    "    ax.tick_params(axis='y', colors=\"C0\")\n",
    "\n",
    "    N = len(scores)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "        running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
    "\n",
    "    ax2.scatter(x, running_avg, color=\"C1\")\n",
    "    ax2.axes.get_xaxis().set_visible(False)\n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.set_ylabel('Score', color=\"C1\")\n",
    "    ax2.yaxis.set_label_position('right')\n",
    "    ax2.tick_params(axis='y', colors=\"C1\")\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            plt.axvline(x=line)\n",
    "\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9298fb-3e4b-44f6-811c-41fd3430ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i+1 for i in range(len(score_history))]\n",
    "plot_learning_curve(x, score_history, filename = 'PPO.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110fea0-5826-47fa-a447-9208b92f218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enviroment_class import CustomEnv\n",
    "\n",
    "env = CustomEnv(obstacle_turn = True,\n",
    "                vizualaze     = False,\n",
    "                Total_war     = True,\n",
    "                inp_dim       = 500,\n",
    "                head_velocity = 0.005,#0.005\n",
    "                num_obs       = 5,\n",
    "                num_enemy     = 1,\n",
    "                size_obs      = [50, 60],\n",
    "                rew_col       = -70,\n",
    "                rew_win       = 100,\n",
    "                rew_defeat    = -100,\n",
    "                steps_limit   = 1000,\n",
    "                EnemyLidSet   = [45,90],\n",
    "                AllyLidSet    = [40, 90])\n",
    "_ = env.reset()\n",
    "\n",
    "\n",
    "env.get_statistic( model = agent, num_games = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0e5a0-ea9f-4902-8fcc-43d6d0ba5499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606f80e-89a8-4fc8-bd62-59881de57829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64f1a9-04f5-4753-a80f-b432f3db38eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6adccc-0cf7-4083-8c38-5e8bcdca7ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ca4ec-8322-482e-bb00-6b8b325dde3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31311b-41b7-4ec0-9e85-d8bca28dec2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
